{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import networkx as nx\n",
    "from math import *\n",
    "import random \n",
    "from numpy import linalg as LA\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score,f1_score\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "U0, v0 = mnist[\"data\"], mnist[\"target\"]\n",
    "U= U0.astype(np.double)\n",
    "v = v0.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_bin_5_lst = [2*int(v[i]==5)-1 for i in range(len(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  775  776  777  778  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   779  780  781  782  783  label  \n",
       "0  0.0  0.0  0.0  0.0  0.0      1  \n",
       "1  0.0  0.0  0.0  0.0  0.0     -1  \n",
       "2  0.0  0.0  0.0  0.0  0.0     -1  \n",
       "3  0.0  0.0  0.0  0.0  0.0     -1  \n",
       "4  0.0  0.0  0.0  0.0  0.0     -1  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_U = pd.DataFrame(data=U)\n",
    "df_v = pd.DataFrame(data=np.asarray(v_bin_5_lst),  columns=['label'])\n",
    "df_data_merged =pd.concat([df_U, df_v.reindex(df_U.index)], axis=1)\n",
    "df_data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df_data_merged, train_set_size,test_set_size,m):\n",
    "    np.random.seed(0)\n",
    "    shuffled_indices = np.random.permutation(len(df_data_merged))\n",
    "    batch_size = int(train_set_size/m)\n",
    "    dic_train_sets_indices= {}\n",
    "    dic_train_sets = {}\n",
    "    for i in range(m):\n",
    "        dic_train_sets_indices[i] = shuffled_indices[i*batch_size:(i+1)*batch_size]\n",
    "        dic_train_sets[i] = df_data_merged.iloc[dic_train_sets_indices[i]]\n",
    "    dic_train_set = {}\n",
    "    dic_train_set_indices = shuffled_indices[:m*batch_size]\n",
    "    dic_train_set[0] = df_data_merged.iloc[dic_train_set_indices]\n",
    "    dic_test_set= {}\n",
    "    test_indices = shuffled_indices[-test_set_size:]\n",
    "    dic_test_set[0] = df_data_merged.iloc[test_indices]\n",
    "    return dic_train_set, dic_train_sets, dic_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_obj_global(x,dic_train,mu_param,m):\n",
    "    output = sum([f_obj_local(x,dic_train[i],mu_param,m) for i in range(m)])\n",
    "    return output\n",
    "\n",
    "def f_obj_local(y,df_data,mu_param,m):\n",
    "    npar_data= (df_data).to_numpy()\n",
    "    nparr_data_transp = npar_data.T\n",
    "    data = nparr_data_transp[:-1,:]\n",
    "    labels =nparr_data_transp[-1:,:]\n",
    "    n_attributes,n_labels = np.shape(data)\n",
    "    x=y.reshape((n_attributes,1))\n",
    "    v1 = np.dot(data.T,x) \n",
    "    v2 = -np.multiply(labels.T,v1)\n",
    "    obj_val = 0\n",
    "    obj_val = sum([v2[i,0] if v2[i,0] > 709 else log(1+exp(v2[i,0])) for i in range(n_labels)])\n",
    "    output = obj_val + mu_param*np.dot(x.T,x)/(2*m)\n",
    "    return output\n",
    "\n",
    "def grad_f_local(x,df_data,mu_param,m):\n",
    "    npar_data= (df_data).to_numpy()\n",
    "    nparr_data_transp = npar_data.T\n",
    "    data = nparr_data_transp[:-1,:]\n",
    "    labels =nparr_data_transp[-1:,:]\n",
    "    n_attributes,n_labels = np.shape(data)\n",
    "    output = np.zeros((n_attributes,1))\n",
    "    output = sum(-(labels[0,i]/(1+exp(min(709,labels[0,i]*np.dot(data[:,i],x)))))*data[:,[i]] for i in range(n_labels)) \n",
    "    return output+mu_param*x/m\n",
    "\n",
    "def grad_f_matrix(x_matrix,dic_train_sets,mu_param):\n",
    "    (m,n) = np.shape(x_matrix)\n",
    "    output = np.zeros((m,n))\n",
    "    for i in range(m):\n",
    "        x = x_matrix[i,:].reshape((n,1))\n",
    "        grad_vec = grad_f_local(x,dic_train_sets[i],mu_param,m)\n",
    "        output[i,:] = grad_vec.reshape((1,n))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_matrix(graph_name,m):\n",
    "    output = np.zeros((m,m))\n",
    "    if m==1:\n",
    "        output =np.array([[1]])\n",
    "    elif graph_name == \"star\":\n",
    "        for i in range(m):\n",
    "            output[i,i]+=0.5\n",
    "            output[i,0]+=0.5\n",
    "    elif graph_name == \"ring\":\n",
    "        for i in range(m):\n",
    "            output[i,i]=0.5\n",
    "            output[np.remainder(i+1,m) ,i]=0.5\n",
    "    elif graph_name == \"line\":\n",
    "        for i in range(m-1):\n",
    "            output[i,i]=0.5\n",
    "            output[i+1 ,i]=0.5\n",
    "        output[0,0]=1\n",
    "        output[m-1,m-1]=0.5\n",
    "        output[2,1]=0\n",
    "        output[2,2]=1\n",
    "    elif graph_name == \"complete\":\n",
    "        output = np.ones((m,m))/(2*(m-1))\n",
    "        for i in range(m):\n",
    "            output[i,i]=0.5\n",
    "        #output = np.ones((m,m))/m \n",
    "    else:\n",
    "        print(\"The graph name is unknown!\")\n",
    "    return output\n",
    "\n",
    "def C_matrix(graph_name,m):\n",
    "    output = R_matrix(graph_name,m).T\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x,data2,labels,mu_param):\n",
    "    data = data2\n",
    "    n_attributes,n_labels = np.shape(data)\n",
    "    output = sum(-(labels[i]/(1+exp(min(709,labels[i]*np.dot(data[:,i],x)))))*data[:,i] \n",
    "                for i in range(n_labels))/n_labels\n",
    "    return output+mu_param*x\n",
    "\n",
    "def obj_function(x,data1,labels,mu_param):\n",
    "    data=data1\n",
    "    n_attributes,n_labels = np.shape(data)\n",
    "    obj_val = 0\n",
    "    v1 = np.dot(data.T,x) \n",
    "    v2 = -np.multiply(labels.T,v1)\n",
    "    for i in range(n_labels):\n",
    "        if v2[i] > 709:\n",
    "            obj_val += v2[i]\n",
    "        else:\n",
    "            obj_val += log(1+exp(v2[i]))\n",
    "    output = np.asscalar((obj_val/n_labels) + (mu_param*np.dot(x.T,x)/2))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushpull(dic_train_sets,max_iter,epoch_size,x0,G_R_name,G_C_name,step_size,mu_param):\n",
    "    (m,n) = np.shape(x0)\n",
    "    R = R_matrix(G_R_name,m)\n",
    "    C = C_matrix(G_C_name,m)    \n",
    "    f_vals = np.zeros(epoch_size+1)\n",
    "    consensus_err_vals = np.zeros(epoch_size+1)\n",
    "    x_matrix_now = x0\n",
    "    x_matrix_next = x0\n",
    "    grad_f_matrix_now = grad_f_matrix(x_matrix_now,dic_train_sets,mu_param)\n",
    "    grad_f_matrix_next = grad_f_matrix(x_matrix_next,dic_train_sets,mu_param) \n",
    "    epoch_index = 0\n",
    "    for k in range(max_iter+1):\n",
    "        x_matrix_now = x_matrix_next\n",
    "        grad_f_matrix_now = grad_f_matrix_next\n",
    "        x_matrix_next = np.dot(R,x_matrix_now - np.dot(np.diag(step_size[0]),grad_f_matrix_now))\n",
    "        grad_f_matrix_next = np.dot(C,grad_f_matrix_now)+grad_f_matrix(x_matrix_next,dic_train_sets,mu_param)-grad_f_matrix(x_matrix_now,dic_train_sets,mu_param)\n",
    "        if max_iter==0 or (k % ceil(max_iter/epoch_size)) == 0:\n",
    "            if m == 1:\n",
    "                x_ave = x_matrix_now[0]\n",
    "            else:\n",
    "                x_ave = x_matrix_now.mean(0)\n",
    "            f_vals[epoch_index] = f_obj_global(x_ave,dic_train_sets,mu_param,m)\n",
    "            consensus_err_vals[epoch_index] = LA.norm(x_matrix_now-np.dot(np.ones((m,1)),x_ave.reshape(1,n)))\n",
    "            epoch_index += 1\n",
    "    return x_matrix_next, f_vals, consensus_err_vals \n",
    "\n",
    "\n",
    "def GDM(dic_train_set,max_iter,epoch_size,x0_GDM,step_size,mu_param):\n",
    "    f_values = np.zeros(epoch_size+1)\n",
    "    (m,n) = np.shape(x0_GDM)\n",
    "    x_now = x0_GDM\n",
    "    x_next = x0_GDM\n",
    "    e=1\n",
    "    consensus_err_vals = np.zeros(epoch_size+1)\n",
    "    epoch_index = 0\n",
    "    for k in range(max_iter+1):\n",
    "        x_now = x_next\n",
    "        x_next = x_now - step_size*grad_f_local(x_now,dic_train_set[0],mu_param,1)\n",
    "        if max_iter==0 or (k % ceil(max_iter/epoch_size)) == 0:\n",
    "            if m == 1:\n",
    "                x_ave = x_now[0]\n",
    "            else:\n",
    "                x_ave = x_now.mean(0)\n",
    "            f_values[epoch_index] = f_obj_global(x_now,dic_train_set,mu_param,1)\n",
    "            consensus_err_vals[epoch_index] = LA.norm(x_now-np.dot(np.ones((m,1)),x_ave.reshape(1,n)))\n",
    "            epoch_index += 1\n",
    "    return x_next, f_values,consensus_err_vals \n",
    "\n",
    "def GD_by_pushpull(dic_train_set,max_iter,epoch_size,x0,step_size,mu_param):\n",
    "    G_R_name = \"complete\"\n",
    "    G_C_name = \"complete\"\n",
    "    return pushpull(dic_train_set,max_iter,epoch_size,x0,G_R_name,G_C_name,step_size,mu_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIGM(data,max_iter,epoch,stepsize,mu_param,m,x0_PIGM):\n",
    "    obj_values = np.zeros((epoch+1,m))\n",
    "    glob_obj_values = np.zeros((epoch+1))\n",
    "    n_attributes,n_labels = np.shape(data[0].values[:,:-1].T)\n",
    "    x_now = np.ones((n_attributes,m+1))\n",
    "    x_next = np.ones((n_attributes,m+1))\n",
    "    consensus_err_vals = np.zeros(epoch_size+1)\n",
    "    x_bar = x_next[:,:-1]\n",
    "    a=1\n",
    "    initial_x = np.ones((n_attributes,1))\n",
    "    extra = initial_x\n",
    "    epoch_index = 0\n",
    "    epoch_index1 = 0\n",
    "    for k in range(max_iter):\n",
    "        x_now = x_next\n",
    "        x_next[:,0] = x_now[:,m]\n",
    "        for l in range(m):\n",
    "            vector =  x_next[:,l] - stepsize*gradient(x_next[:,l],data[l].values[:,:-1].T ,data[l].values[:,-1].T,mu_param)\n",
    "            #print(vector)\n",
    "            #print(vector.shape)\n",
    "            for i in range(n_attributes):\n",
    "                x_next[i,l+1] = min(max(-1000,vector[0][i]),1000)\n",
    "            #    if vector[0][i]>-1000:\n",
    "            #        dummy = vector[0][i]\n",
    "            #    else:\n",
    "            #        dummy = -1000\n",
    "            #    if(dummy<1000):\n",
    "            #        dummy = dummy\n",
    "            #    else:\n",
    "            #        dummy = 1000\n",
    "            #    x_next[i,l+1] = dummy \n",
    "        if k==0:\n",
    "            x_bar = x_next.T[:-1][0]\n",
    "        else:\n",
    "            x_bar = x_next.T[:-1].mean(0)\n",
    "        if (k % ceil(max_iter/epoch)) == 0:\n",
    "            for count in range(m):\n",
    "                obj_values[epoch_index,count] = obj_function(x_next[:,count],data[count].values[:,:-1].T,data[count].values[:,-1].T,mu_param)\n",
    "            glob_obj_values[epoch_index] = sum([obj_values[epoch_index,j] for j in range(m)])\n",
    "            consensus_err_vals[epoch_index] = LA.norm(x_next.T[:-1]-np.dot(np.ones((m,1)),x_bar.reshape(1,n_attributes)))\n",
    "            epoch_index += 1\n",
    "        glob_obj_values[epoch] =glob_obj_values[epoch-1]\n",
    "        consensus_err_vals[epoch] = consensus_err_vals[epoch-1]\n",
    "    return x_bar.reshape((1,n_attributes)), glob_obj_values,consensus_err_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_func(e):\n",
    "    if e > 709:\n",
    "        dummy = 1\n",
    "    elif e < -709:\n",
    "        dummy = -1\n",
    "    else:\n",
    "        dummy = (exp(e)-exp(-e))/(exp(e)+exp(-e))\n",
    "    return dummy\n",
    "\n",
    "def f_grad(x, u, v):\n",
    "    a = np.insert(u, 0, 1)\n",
    "    a.reshape(len(a), 1)\n",
    "    grad = (phi_func(a.T@x)-v)*(1-(phi_func(a.T@x))**2)*a\n",
    "    return grad\n",
    "\n",
    "def h_func(x, u):\n",
    "    h=phi_func(x[0]+x[1]*u)\n",
    "    return h\n",
    "\n",
    "def obj_function(x,u,v):\n",
    "    n_attributes, n_labels = u.shape\n",
    "    total = 0\n",
    "    for i in range(n_labels):\n",
    "        total += ((h_func(x,u[0,i])-v[0,i])**2)/2\n",
    "    return total/n_labels\n",
    "       \n",
    "def SGD(train_set_size, data, labels, max_iter, epoch_size, sample, x_init, step_size):\n",
    "    f_values=np.zeros([epoch_size+1,sample])\n",
    "    for j in range(sample):\n",
    "        x_now = x_init \n",
    "        x_next = x_init \n",
    "        epoch_index = 0\n",
    "        for k in range(max_iter+1):\n",
    "            i = np.random.randint(train_set_size) \n",
    "            n_attributes,n_labels = np.shape(data)\n",
    "            u = data[:, i]\n",
    "            v = labels[0, i]\n",
    "            x_next=x_now-step_size*f_grad(x_now,u,v)\n",
    "            x_now=x_next\n",
    "            if max_iter==0 or (k % ceil(max_iter/epoch_size))==0:\n",
    "                f_values[epoch_index,j] = obj_function(x_now,data,labels)\n",
    "                epoch_index += 1\n",
    "    return f_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_confu_mat(dic_test_set,opt_sol):\n",
    "    npar_data= (dic_test_set[0]).to_numpy()\n",
    "    test_data = npar_data[:,:-1]\n",
    "    test_labels =npar_data[:,-1:]\n",
    "    test_set_size = len(dic_test_set[0])\n",
    "    pred_labels = np.zeros((test_set_size,1))\n",
    "    for j in range(test_set_size):\n",
    "        pred_labels[j][0] = np.sign(np.dot(test_data[j,:],opt_sol))\n",
    "    output = confusion_matrix(test_labels, pred_labels)\n",
    "    return output\n",
    "\n",
    "def precision_score(dic_test_set,opt_sol):\n",
    "    confu_mat = my_confu_mat(dic_test_set,opt_sol)\n",
    "    output = confu_mat[1][1]/(confu_mat[1][0]+confu_mat[1][1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_attributes = 1\n",
    "n_labels = 70000\n",
    "np.random.seed(1)\n",
    "mu, sigma = 10, 100\n",
    "rnd_data = np.random.normal(mu, sigma, size=[n_labels, n_attributes])\n",
    "#rnd_labels = 2*np.reshape(np.random.randint(2, size=n_labels),(n_labels,1)) - np.ones((n_labels,1))\n",
    "\n",
    "df_rnd_data = pd.DataFrame(data=rnd_data )\n",
    "df_rnd_labels = pd.DataFrame(data=np.asarray(v_bin_5_lst),  columns=['label'])\n",
    "df_data_merged_rnd =pd.concat([df_rnd_data, df_rnd_labels.reindex(df_rnd_data.index)], axis=1)\n",
    "# df_data_merged_rnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size, test_set_size, m = 1000, 1000, 5\n",
    "dic_train_set, dic_train_sets, dic_test_set = split_train_test(df_data_merged_rnd, train_set_size, test_set_size, m)\n",
    "df = dic_train_sets[0]\n",
    "dataset= (df).to_numpy()\n",
    "data_new = dataset.T\n",
    "data = data_new[:-1,:]\n",
    "labels =data_new[-1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_attributes = len(df_data_merged_rnd.columns)-1\n",
    "n_labels = len(df_data_merged_rnd)\n",
    "mu_param = 10^-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ini = np.zeros([agents,attributes])\n",
    "def argmin(x_block,x,y):\n",
    "    ### minimizer for x_tilda\n",
    "    \n",
    "def r0():\n",
    "    \n",
    "    \n",
    "def smooth(x,m): ### Incorrect m(agents)\n",
    "    lamda = 0.15 #given\n",
    "    r = lamda* sum(r0(x[j]) for j in range(m))\n",
    "    \n",
    "\n",
    "def del_x(i,j,x,x_big,y_big,l,agents,pass_value): # x is the block of a single agent\n",
    "    if i == j & pass_value == False:\n",
    "        delta_x = np.zeros([x.shape[0]])\n",
    "    else:\n",
    "        x_tilda = argmin(x,x_big,y_big) + smooth(x,agents)\n",
    "        delta_x = x_tilda - x #should be an array\n",
    "    return delta_x\n",
    "\n",
    "def graph_connection(i, agents, A_matrix):\n",
    "    return agents[np.where(A_matrix[i,:] != 0)]\n",
    "    \n",
    "def graph_passing(i, agents, l, l_agent_new, Ni):\n",
    "    if len(np.where(l_agent_new = l)) != 0:\n",
    "        nit = Ni.intersection(agents[np.where(l_agent_new = l)])\n",
    "    else:\n",
    "        nit = np.array([])\n",
    "    if len(nilt) == 0:\n",
    "        nilt = i\n",
    "        pass_value = False\n",
    "    else:\n",
    "        nilt = nit\n",
    "        pass_value = True\n",
    "    return nilt, pass_value\n",
    "\n",
    "def func_a(i, j, A_matrix, pass_value):\n",
    "    if j == i & pass_value == False:    \n",
    "        a = 1\n",
    "    else:\n",
    "        a = A_matrix[i,j]\n",
    "    return a\n",
    "\n",
    "def block_sonata(dic_train_set, attributes, gamma, blocks, agents, max_iter, A_matrix):\n",
    "    phi_now = np.ones([agents,blocks])\n",
    "    phi_next = np.ones([agents,blocks])\n",
    "    x_now = np.ones([agents,attributes])\n",
    "    x_next = np.ones([agents,attributes])\n",
    "    y_now = np.ones([agents,attributes])\n",
    "    y_next = np.ones([agents,attributes])\n",
    "    grad_now = np.ones([agents,attributes])\n",
    "    grad_next = np.ones([agents,attributes])\n",
    "    length = int(attributes/blocks)\n",
    "    l_agent_new = random.randint(0,blocks,agents)\n",
    "    f_values = np.zeros(epoch_size+1)\n",
    "    for k in range(max_iter):\n",
    "        l_agent = l_agent_new\n",
    "        l_agent_new = random.randint(0,blocks,agents)\n",
    "        gamma_new = gamma ** (k+1)\n",
    "        for i in range(agents):\n",
    "            Ni = graph_connection(i, agents, A_matrix)\n",
    "            Nilt, pass_value = graph_passing(i, agents, l, l_agent_new, Ni)\n",
    "            for l in range(blocks):\n",
    "                x_now_block = x_now[i,l*length:(l+1)*length]\n",
    "\n",
    "                phi_next[i,l] = sum(func_a(i, j, A_matrix, pass_value)*phi_now[j,l] for j in range(Nilt))\n",
    "                x_now_block = x_now[j,l*length:(l+1)*length]\n",
    "                x_next_block = sum((func_a(i, j, A_matrix, pass_value)*phi_now[j,l]*\n",
    "                                    (x_now[j,l*length:(l+1)*length]+gamma_new*del_x(i,j,x_now_block, x_now[j,:],y_now[j,:],l,agents,pass_value))\n",
    "                                            for j in range(Nilt))/phi_next[i,l]       \n",
    "                x_next[i,l*length:(l+1)*length] = x_next_block\n",
    "                                   \n",
    "                y_now_block= y_now[i,l*length:(l+1)*length]\n",
    "                grad_next_block= grad_func(grad_now[i,l*length:(l+1)*length],l,l_agent)\n",
    "                y_next_block = sum((func_a(i,j,l,l_agent,Ni)) \n",
    "                                   *(phi_now[j,l]*y_now[j,l*length:(l+1)*length]) for j in range(Nilt))/phi_next[i,l] \n",
    "                                   +((grad_next_block-grad_now_block)/phi_next[i,l])\n",
    "                            \n",
    "                x_next[i,l*length:(l+1)*length] = x_next_block\n",
    "                y_next[i,l*length:(l+1)*length] = y_next_block\n",
    "                grad_next[i,l*length:(l+1)*length] = grad_next_block\n",
    "        if max_iter==0 or (k % ceil(max_iter/epoch_size)) == 0:    \n",
    "            f_values[epoch_index] = f_obj(x_now)\n",
    "            epoch_index += 1\n",
    "                                   \n",
    "        x_now=x_next      \n",
    "        y_now=y_next\n",
    "        phi_now=phi_next     \n",
    "        grad_now=grad_next\n",
    "        \n",
    "        return x_now,f_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation for training the optimization model\n",
    "attributes = len(dic_train_set[0].columns)-1\n",
    "labels = len(dic_train_set[0])\n",
    "mu = 10**(-3)\n",
    "epoch_size = 5\n",
    "max_iter = n_labels*epoch_size\n",
    "step_size = 0.3\n",
    "lamda = 0.15\n",
    "theta = 0.7\n",
    "\n",
    "X_sol_BS,f_vals_BS = block_sonata(dic_train_set, attributes, gamma, blocks, agents, max_iter, A_matrix)\n",
    "    \n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "\n",
    "plt.plot(range(0,max_iter+1,ceil(max_iter/epoch_size)),f_vals_BS.tolist(),color='black',\n",
    "         marker='v',markersize=10,linestyle='solid',label=\"Block-sonata\",linewidth=4)\n",
    "\n",
    "plt.legend(loc=3,fontsize=12)\n",
    "plt.xlabel('Number of single gradient evaluations', color='#1C2833',fontsize=12)\n",
    "plt.ylabel(\"Objective function value\", color='#1C2833',fontsize=18)\n",
    "\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= [4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "li=np.zeros([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-188f96ee0926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mli\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "li.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = phi[2][4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "5\n",
      "8\n",
      "2\n",
      "0\n",
      "10\n",
      "0\n",
      "9\n",
      "4\n",
      "7\n",
      "8\n",
      "4\n",
      "1\n",
      "6\n",
      "2\n",
      "6\n",
      "2\n",
      "8\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(random.randint(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
